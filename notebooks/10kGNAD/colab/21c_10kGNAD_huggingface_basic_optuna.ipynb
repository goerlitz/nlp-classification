{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goerlitz/nlp-classification/blob/main/notebooks/10kGNAD/colab/21c_10kGNAD_huggingface_basic_optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrveYRYD2E9-"
      },
      "source": [
        "# Hyperparameter Optimization with HuggingFace Transformers\n",
        "\n",
        "Adapted from https://huggingface.co/docs/transformers/custom_datasets#sequence-classification-with-imdb-reviews\n",
        "\n",
        "Things we need\n",
        "* a tokenizer\n",
        "* tokenized input data\n",
        "* a pretrained model\n",
        "* evaluation metrics\n",
        "* training parameters\n",
        "* a Trainer instance\n",
        "\n",
        "Notes\n",
        "* [class labels can be included in the model config](https://github.com/huggingface/transformers/pull/2945#issuecomment-781986506) (a bit hacky)\n",
        "* [fp16 is disabled on tesla P100 GPU in pytorch](https://discuss.pytorch.org/t/cnn-fp16-slower-than-fp32-on-tesla-p100/12146)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH5VyX6w9AIM"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L2BZ9NGbmTkF"
      },
      "outputs": [],
      "source": [
        "# checkpoint = \"distilbert-base-german-cased\"\n",
        "checkpoint = \"deepset/gbert-base\"\n",
        "# checkpoint = \"deepset/gelectra-base\"\n",
        "\n",
        "project_name = f'10kgnad_hf__{checkpoint.replace(\"/\", \"_\")}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKqjLlGpWdsi"
      },
      "source": [
        "### Connect Google Drive\n",
        "\n",
        "Will be used to save results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YXxAbtZWcxA",
        "outputId": "ad8f82e4-2aa3-4f49-d4b1-098b7c412795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M3n8HqXwEyK6"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# define model path\n",
        "root_path = Path('/content/gdrive/My Drive/')\n",
        "base_path = root_path / 'Colab Notebooks/nlp-classification/'\n",
        "model_path = base_path / 'models'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F2oddvs2rNv"
      },
      "source": [
        "## Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVWRNvQf1cnR",
        "outputId": "8559ba67-d8ac-416d-a50a-60a9235a82d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan  9 14:28:50 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    32W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwlw_kI3nHLW"
      },
      "source": [
        "### Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QhKj625lBso",
        "outputId": "87ff547f-ba75-4a37-8fd0-acad85243e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optuna==2.10.0\n",
            "transformers==4.15.0\n",
            "torch @ https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "CPU times: user 105 ms, sys: 56.5 ms, total: 162 ms\n",
            "Wall time: 10.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!pip install -q -U transformers datasets >/dev/null\n",
        "!pip install -q -U optuna >/dev/null\n",
        "\n",
        "# check installed version\n",
        "!pip freeze | grep optuna        # optuna==2.10.0\n",
        "!pip freeze | grep transformers  # transformers==4.15.0\n",
        "!pip freeze | grep \"torch \"      # torch==1.10.0+cu111"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vbpLzC7DRoR5"
      },
      "outputs": [],
      "source": [
        "from transformers import logging\n",
        "\n",
        "# hide progress bar when downloading tokenizer and model (a workaround!)\n",
        "logging.get_verbosity = lambda : logging.NOTSET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64Q8bFMM7UYg"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "355a2b3420774838b9361b490ad4c958",
            "8f4acce1e6f442e9930eef396b00aedd",
            "753b7b3f9ef045488e90aef50eee4b42",
            "65b73b2ae1a44b3e87bef25762dae19c",
            "01581091bb0f437a9592d1841beea701",
            "db34d57214034bdb8687b232089d840c",
            "0f8d0ce4d4fb4c09bfeb11f2cab4fd4b",
            "7cae5fdfa9924e77a7d59576e78415f5",
            "ff32d8c622774e538ee8bdadf3393093",
            "98e188919de44a2e85f0004010ebee49",
            "8c6ba294e8dd41ab9614971767b4be1d"
          ]
        },
        "id": "4aYzOljo7W9X",
        "outputId": "eb17c1f6-52c8-455d-d5d8-496bd4119b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-0e1a53e9f937c1cf\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-0e1a53e9f937c1cf/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "355a2b3420774838b9361b490ad4c958",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0e1a53e9f937c1cf/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-59d70429eaf283cf.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0e1a53e9f937c1cf/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-a2cd8f79c68f7005.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0e1a53e9f937c1cf/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-5dec691e070de180.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0e1a53e9f937c1cf/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-7ee1cd4bfba8d7d3.arrow\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# gnad10k = load_dataset(\"gnad10\")\n",
        "# label_names = gnad10k[\"train\"].features[\"label\"].names\n",
        "\n",
        "base_url = \"https://raw.githubusercontent.com/tblock/10kGNAD/master/{}.csv\"\n",
        "data_files = {x: base_url.format(x) for x in [\"train\", \"test\"]}\n",
        "gnad10k = (load_dataset('csv',\n",
        "                        data_files=data_files,\n",
        "                        sep=\";\",\n",
        "                        quotechar=\"'\",\n",
        "                        names=[\"label\", \"text\"]).\n",
        "           class_encode_column(\"label\"))\n",
        "\n",
        "label_names = gnad10k[\"train\"].features[\"label\"].names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkcJyc-I8bLP",
        "outputId": "3133e283-4813-41a8-a201-cfa21318f9b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['label', 'text'],\n",
            "        num_rows: 9245\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['label', 'text'],\n",
            "        num_rows: 1028\n",
            "    })\n",
            "})\n",
            "labels: ['Etat', 'Inland', 'International', 'Kultur', 'Panorama', 'Sport', 'Web', 'Wirtschaft', 'Wissenschaft']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 5,\n",
              " 'text': '21-Jähriger fällt wohl bis Saisonende aus. Wien – Rapid muss wohl bis Saisonende auf Offensivspieler Thomas Murg verzichten. Der im Winter aus Ried gekommene 21-Jährige erlitt beim 0:4-Heimdebakel gegen Admira Wacker Mödling am Samstag einen Teilriss des Innenbandes im linken Knie, wie eine Magnetresonanz-Untersuchung am Donnerstag ergab. Murg erhielt eine Schiene, muss aber nicht operiert werden. Dennoch steht ihm eine mehrwöchige Pause bevor.'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(gnad10k)\n",
        "print(\"labels:\", label_names)\n",
        "gnad10k[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EUOwFbFPXCy"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "* Loading the same Tokenizer that was used with the pretrained model.\n",
        "* Define function to tokenize the text (with truncation to max input length of model.\n",
        "* Run the tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5a7a62e38a414f93a0bc606ffb332598",
            "17c6e3596d7540c293dc1bec00e7fdc5",
            "768ce8b64cc64e03935427b8154336ea",
            "ab57ee6611f3437ea441244f126d5e95",
            "ebfd5be419bf475482d88259eee4f02f",
            "9efe16d403d34e788ac4d944eca683f3",
            "793864aaa59243848602d2fbbd0c3ffb",
            "f01a034dd014421da2b6d8cf9997f15a",
            "d71c4c42b297483fb225519681386452",
            "0c3f043d41fe48feb784ed760b2f32c1",
            "5a8bb998beae4c3f906ed3c35ac57b6d"
          ]
        },
        "id": "u7AJ7SGjPaZ0",
        "outputId": "056738bf-ff8f-43ed-963a-ddccbb602acf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0e1a53e9f937c1cf/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-3a71e492fa9729cb.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a7a62e38a414f93a0bc606ffb332598",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_gnad10k = gnad10k.map(preprocess_function, batched=True).remove_columns(\"text\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdmFxnHlSV6x"
      },
      "source": [
        "### Use Dynamic Padding\n",
        "\n",
        "Apply panding only on longest text in batch - this is more efficient than applying padding on the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DhEWeeg2SVCe"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqe_fA8muv5T"
      },
      "source": [
        "## Model Setup\n",
        "\n",
        "We want to include the label names and save them together with the model.\n",
        "The only way to do this is to create a Config and put them in. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kHPXNqxCgyxQ"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "        checkpoint,\n",
        "        num_labels=len(label_names),\n",
        "        id2label={i: label for i, label in enumerate(label_names)},\n",
        "        label2id={label: i for i, label in enumerate(label_names)},\n",
        "        )\n",
        "\n",
        "def model_init(trial: optuna.Trial):\n",
        "    \"\"\"A function that instantiates the model to be used.\"\"\"\n",
        "    return AutoModelForSequenceClassification.from_pretrained(checkpoint, config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufbNYVSIxuhv"
      },
      "source": [
        "### Define Evaluation Metrics\n",
        "\n",
        "The funtion that computes the metrics needs to be passed to the Trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Hpj1PZYjxtqS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, matthews_corrcoef\n",
        "import numpy as np\n",
        "from typing import Dict\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    \"\"\"The function that will be used to compute metrics at evaluation.\n",
        "    Must take a :class:`~transformers.EvalPrediction` and return a dictionary\n",
        "    string to metric values.\"\"\"\n",
        "    logits, labels = eval_preds\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"acc\": accuracy_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds, average='macro'),\n",
        "        \"precision\": precision_score(labels, preds, average='macro'),\n",
        "        \"recall\": recall_score(labels, preds, average='macro'),\n",
        "        \"mcc\": matthews_corrcoef(labels, preds),\n",
        "        }\n",
        "\n",
        "\n",
        "# def objective(metrics: Dict[str, float]):\n",
        "#     \"\"\"A function computing the main optimization objective from the metrics\n",
        "#     returned by the :obj:`compute_metrics` method.\n",
        "#     To be used in :obj:`Trainer.hyperparameter_search`.\"\"\"\n",
        "#     return metrics[\"eval_loss\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9HHIeJrM3_I"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3_9Al_rbBrla"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainerCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.study._study_direction import StudyDirection\n",
        "import pandas as pd\n",
        "\n",
        "# https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/trainer_callback.py#L505\n",
        "# https://huggingface.co/docs/transformers/main_classes/callback#transformers.TrainerCallback\n",
        "\n",
        "import logging\n",
        "logging.getLogger(__name__).setLevel(logging.INFO)\n",
        "log = logging.getLogger(__name__)\n",
        "\n",
        "class TrialLogAndPruningCallback(TrainerCallback):\n",
        "    \"\"\"Stores eval metrics at each evaluation step in the trial user attrs.\"\"\"\n",
        "    def __init__(self, trial: optuna.Trial, objectives=None, warmup_steps=0, min_trials=7):\n",
        "        self.study = trial.study\n",
        "        self.trial = trial\n",
        "        self.param_keys = [\"num_train_epochs\", \"per_device_train_batch_size\"]\n",
        "        self.param_vals = [trial.params[k] for k in self.param_keys]\n",
        "\n",
        "        log.warning(f\"fixed params: {list(zip(self.param_keys, self.param_vals))}\")\n",
        "\n",
        "        if objectives == None:\n",
        "            self.objectives = [\"eval_loss\"]\n",
        "        else:\n",
        "            self.objectives = objectives\n",
        "        self._warmup_steps = warmup_steps\n",
        "        self._min_trials = max(1, int(min_trials))\n",
        "\n",
        "        log.warning(f\"objectives: {self.objectives}, directions: {self.study.directions}, warmup={self._warmup_steps}, min_trials={self._min_trials}\")\n",
        "        \n",
        "\n",
        "    def _filter_trials(self, complete_trials):\n",
        "        \"\"\"Select only trials with same parameter values\"\"\"\n",
        "        # values = [self.trial.params[k] for k in keys]\n",
        "        return [t for t in complete_trials if self.param_vals == [t.params[k] for k in self.param_keys]]\n",
        "\n",
        "    def _prune(self, step: int, metrics) -> bool:\n",
        "        \"\"\"Median Pruning on multiple objectives.\"\"\"\n",
        "        if step < self._warmup_steps:\n",
        "            # log.warning(f\"less than warmup steps {step}<{self._warmup_steps}\")\n",
        "            return False\n",
        "\n",
        "        # get all completed trials\n",
        "        complete_trials = self.study.get_trials(deepcopy=False,\n",
        "                                                states=[TrialState.COMPLETE])\n",
        "        # only compare trials with same batch size and epochs\n",
        "        complete_trials = self._filter_trials(complete_trials)\n",
        "        n_trials = len(complete_trials)\n",
        "\n",
        "        # check minimal number of trial required\n",
        "        if n_trials < self._min_trials:\n",
        "            # log.warning(f\"less than min trials {n_trials}<{self._min_trials}\")\n",
        "            return False\n",
        "\n",
        "        # log.warning(f\"checking {step}: {metrics}\")\n",
        "\n",
        "        # sanity check\n",
        "        has_metrics = [o in metrics.keys() for o in self.objectives]\n",
        "        if not all(has_metrics):\n",
        "            log.warning(f\"missing objective metrics {list(zip(self.objectives, has_metrics))}\")\n",
        "\n",
        "        # extract metrics from trials\n",
        "        # print(f\"fetching metrics of {n_trials} complete trials\")\n",
        "        trial_metrics = []\n",
        "        for t in complete_trials:\n",
        "            # print(str(step), \"in keys?\", str(step) in t.user_attrs.keys(), t.user_attrs.keys())\n",
        "            if str(step) in t.user_attrs.keys():\n",
        "                trial_metrics.append(t.user_attrs[str(step)])\n",
        "        n_metrics = len(trial_metrics)\n",
        "\n",
        "        # compute median for each metric over all trials\n",
        "        median = pd.DataFrame(trial_metrics).median()\n",
        "\n",
        "        # log.warning(f\"median of {n_metrics}/{n_trials}: {median.to_dict()}\")\n",
        "\n",
        "        # compare current metric value with median\n",
        "        prune_state = []\n",
        "        for i, o in enumerate(self.objectives):\n",
        "            if self.study.directions[i] == StudyDirection.MAXIMIZE:\n",
        "                prune_state.append(metrics[o] <= median[o])\n",
        "            else:\n",
        "                prune_state.append(metrics[o] > median[o])\n",
        "        \n",
        "        met = \",\".join([f\"{m}={metrics[m]:.4}/{median[m]:.4}\" for m in self.objectives])\n",
        "        print(f\"prune? step={step}, warmup={self._warmup_steps}, complete_trials={n_trials}, metrics={n_metrics} -> {met}; {prune_state}\")\n",
        "\n",
        "        # all metrics must be marked for pruning\n",
        "        return all(prune_state)\n",
        "    \n",
        "    def on_evaluate(self, args, state, control, lr_scheduler, metrics, **kwargs):\n",
        "        step = state.global_step\n",
        "        values = {**metrics, \"lr\": lr_scheduler.get_last_lr()[-1]}\n",
        "        self.trial.set_user_attr(str(step), values)\n",
        "\n",
        "        # pruning\n",
        "        if self._prune(step, metrics):\n",
        "            print(f\"pruning trial at step {step}\")\n",
        "            # control.should_training_stop = True  # not needed\n",
        "            raise optuna.TrialPruned()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YqjuJ-2tRMYQ"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import shutil\n",
        "\n",
        "def hp_space(trial: optuna.Trial):\n",
        "    \"\"\"A function that defines the hyperparameter search space.\n",
        "    To be used in :obj:`Trainer.hyperparameter_search`.\"\"\"\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-4, log=True),  # distilbert/bert\n",
        "        # \"learning_rate\": trial.suggest_float(\"learning_rate\", 6e-5, 2e-4, log=True),  # electra\n",
        "        # \"num_train_epochs\": trial.suggest_categorical(\"num_train_epochs\", [1]),\n",
        "        \"num_train_epochs\": trial.suggest_categorical(\"num_train_epochs\", [2, 3]),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16]),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-3, 1e-2, log=True),\n",
        "        # \"weight_decay\": trial.suggest_categorical(\"weight_decay\", [1e-3, 0.0]),\n",
        "    }\n",
        "\n",
        "best_model_dir = \"best_model_trainer\"\n",
        "\n",
        "def best_model_callback(study, trial):\n",
        "    \"\"\"Save the model from a best trial\"\"\"\n",
        "    for t in study.best_trials:\n",
        "        if t.number == trial.number:\n",
        "            print(\"This is a new besttrial\", trial.number)\n",
        "        \n",
        "            out_filename = model_path / f\"{project_name}_t{trial.number}\"\n",
        "            shutil.make_archive(out_filename, 'zip', f\"{project_name}/{best_model_dir}\")\n",
        "\n",
        "def objective(trial: optuna.Trial):\n",
        "\n",
        "    # get hyperparameters choice\n",
        "    hp = hp_space(trial)\n",
        "    lr = hp[\"learning_rate\"]\n",
        "    bs = hp[\"per_device_train_batch_size\"]\n",
        "    epochs = hp[\"num_train_epochs\"]\n",
        "    weight_decay = hp[\"weight_decay\"]\n",
        "    # label_smoothing_factor = hp[\"label_smoothing_factor\"]\n",
        "\n",
        "    eval_rounds_per_epoch = 5\n",
        "    eval_steps = gnad10k[\"train\"].num_rows / bs // eval_rounds_per_epoch\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=str(project_name),\n",
        "        report_to=[],\n",
        "        log_level=\"error\",\n",
        "        disable_tqdm=False,\n",
        "\n",
        "        evaluation_strategy=\"steps\",\n",
        "        eval_steps=eval_steps,\n",
        "        logging_steps=eval_steps,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=eval_steps,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_loss\",\n",
        "        greater_is_better=False,\n",
        "\n",
        "        # hyperparameters\n",
        "        num_train_epochs=epochs,\n",
        "        learning_rate=lr,\n",
        "        per_device_train_batch_size=bs,\n",
        "        per_device_eval_batch_size=bs,\n",
        "        weight_decay=weight_decay,\n",
        "        # label_smoothing_factor=label_smoothing_factor,\n",
        "\n",
        "        # fp16=True,  # fp16 is disabled on Tesla P100 by pytorch\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model_init=model_init,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_gnad10k[\"train\"],\n",
        "        eval_dataset=tokenized_gnad10k[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[TrialLogAndPruningCallback(trial, objectives=[\"eval_loss\", \"eval_f1\"], min_trials=7, warmup_steps=eval_steps*3)]\n",
        "        # callbacks=[TrialPruningCallback(trial)]\n",
        "    )\n",
        "\n",
        "    # train model and save best model from evaluations\n",
        "    # needs 'load_best_model_at_end=True'\n",
        "    trainer.train()\n",
        "    trainer.save_model(f\"{project_name}/{best_model_dir}\")\n",
        "\n",
        "    result = trainer.evaluate(eval_dataset=tokenized_gnad10k[\"test\"])\n",
        "\n",
        "    # store eval metrics in trial\n",
        "    trial.set_user_attr(\"eval_result\", result)\n",
        "    \n",
        "    # return result[\"eval_loss\"]\n",
        "    return result[\"eval_loss\"], result[\"eval_f1\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9knsvQTUxjWi"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SNx_dukVxizp",
        "outputId": "bbcfbf93-e0dd-4b4e-8915-c925107079b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-09 14:29:21,365]\u001b[0m Using an existing study with name 'deepset/gbert-base_loss-f1_bs16_epoch23' instead of creating a new one.\u001b[0m\n",
            "fixed params: [('num_train_epochs', 2), ('per_device_train_batch_size', 16)]\n",
            "objectives: ['eval_loss', 'eval_f1'], directions: [<StudyDirection.MINIMIZE: 1>, <StudyDirection.MAXIMIZE: 2>], warmup=345.0, min_trials=7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1156' max='1156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1156/1156 21:02, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Mcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.888300</td>\n",
              "      <td>0.468282</td>\n",
              "      <td>0.851167</td>\n",
              "      <td>0.842690</td>\n",
              "      <td>0.841975</td>\n",
              "      <td>0.850380</td>\n",
              "      <td>0.830280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.469300</td>\n",
              "      <td>0.417981</td>\n",
              "      <td>0.872568</td>\n",
              "      <td>0.870239</td>\n",
              "      <td>0.870143</td>\n",
              "      <td>0.877034</td>\n",
              "      <td>0.854881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.430200</td>\n",
              "      <td>0.430449</td>\n",
              "      <td>0.864786</td>\n",
              "      <td>0.856578</td>\n",
              "      <td>0.856275</td>\n",
              "      <td>0.871952</td>\n",
              "      <td>0.847203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.369300</td>\n",
              "      <td>0.425328</td>\n",
              "      <td>0.868677</td>\n",
              "      <td>0.868235</td>\n",
              "      <td>0.873588</td>\n",
              "      <td>0.876157</td>\n",
              "      <td>0.851837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.393600</td>\n",
              "      <td>0.327018</td>\n",
              "      <td>0.893969</td>\n",
              "      <td>0.893994</td>\n",
              "      <td>0.896787</td>\n",
              "      <td>0.891618</td>\n",
              "      <td>0.878511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.197100</td>\n",
              "      <td>0.348116</td>\n",
              "      <td>0.889105</td>\n",
              "      <td>0.888157</td>\n",
              "      <td>0.887540</td>\n",
              "      <td>0.891538</td>\n",
              "      <td>0.873397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>805</td>\n",
              "      <td>0.185300</td>\n",
              "      <td>0.373460</td>\n",
              "      <td>0.898833</td>\n",
              "      <td>0.894175</td>\n",
              "      <td>0.894044</td>\n",
              "      <td>0.898662</td>\n",
              "      <td>0.884433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.196500</td>\n",
              "      <td>0.350003</td>\n",
              "      <td>0.894942</td>\n",
              "      <td>0.892846</td>\n",
              "      <td>0.894190</td>\n",
              "      <td>0.893610</td>\n",
              "      <td>0.879757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1035</td>\n",
              "      <td>0.178600</td>\n",
              "      <td>0.361307</td>\n",
              "      <td>0.896887</td>\n",
              "      <td>0.891236</td>\n",
              "      <td>0.890821</td>\n",
              "      <td>0.894634</td>\n",
              "      <td>0.882168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.204800</td>\n",
              "      <td>0.341575</td>\n",
              "      <td>0.900778</td>\n",
              "      <td>0.898400</td>\n",
              "      <td>0.898327</td>\n",
              "      <td>0.900101</td>\n",
              "      <td>0.886469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-09 14:50:55,392]\u001b[0m Trial 1 finished with values: [0.3270176947116852, 0.8939935101635533] and parameters: {'learning_rate': 4.772157231652486e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 16, 'weight_decay': 0.009565604336674773}. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a new besttrial 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "fixed params: [('num_train_epochs', 2), ('per_device_train_batch_size', 16)]\n",
            "objectives: ['eval_loss', 'eval_f1'], directions: [<StudyDirection.MINIMIZE: 1>, <StudyDirection.MAXIMIZE: 2>], warmup=345.0, min_trials=7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1156' max='1156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1156/1156 21:04, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Mcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.850700</td>\n",
              "      <td>0.536545</td>\n",
              "      <td>0.827821</td>\n",
              "      <td>0.827060</td>\n",
              "      <td>0.827723</td>\n",
              "      <td>0.838801</td>\n",
              "      <td>0.805282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.498600</td>\n",
              "      <td>0.420047</td>\n",
              "      <td>0.869650</td>\n",
              "      <td>0.868153</td>\n",
              "      <td>0.869650</td>\n",
              "      <td>0.871935</td>\n",
              "      <td>0.851295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.447400</td>\n",
              "      <td>0.426456</td>\n",
              "      <td>0.868677</td>\n",
              "      <td>0.860825</td>\n",
              "      <td>0.855087</td>\n",
              "      <td>0.877051</td>\n",
              "      <td>0.851047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.397400</td>\n",
              "      <td>0.460185</td>\n",
              "      <td>0.861868</td>\n",
              "      <td>0.855141</td>\n",
              "      <td>0.861475</td>\n",
              "      <td>0.860800</td>\n",
              "      <td>0.843079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.408700</td>\n",
              "      <td>0.350615</td>\n",
              "      <td>0.892996</td>\n",
              "      <td>0.893079</td>\n",
              "      <td>0.894750</td>\n",
              "      <td>0.893473</td>\n",
              "      <td>0.877762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.198400</td>\n",
              "      <td>0.363162</td>\n",
              "      <td>0.892023</td>\n",
              "      <td>0.890912</td>\n",
              "      <td>0.889150</td>\n",
              "      <td>0.894771</td>\n",
              "      <td>0.876670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>805</td>\n",
              "      <td>0.180900</td>\n",
              "      <td>0.371381</td>\n",
              "      <td>0.898833</td>\n",
              "      <td>0.894341</td>\n",
              "      <td>0.892211</td>\n",
              "      <td>0.898438</td>\n",
              "      <td>0.884261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.212600</td>\n",
              "      <td>0.348848</td>\n",
              "      <td>0.901751</td>\n",
              "      <td>0.897115</td>\n",
              "      <td>0.900159</td>\n",
              "      <td>0.896737</td>\n",
              "      <td>0.887674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1035</td>\n",
              "      <td>0.190700</td>\n",
              "      <td>0.353676</td>\n",
              "      <td>0.907588</td>\n",
              "      <td>0.902728</td>\n",
              "      <td>0.898042</td>\n",
              "      <td>0.909873</td>\n",
              "      <td>0.894481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.209900</td>\n",
              "      <td>0.337582</td>\n",
              "      <td>0.907588</td>\n",
              "      <td>0.902066</td>\n",
              "      <td>0.899982</td>\n",
              "      <td>0.904906</td>\n",
              "      <td>0.894229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-09 15:12:55,083]\u001b[0m Trial 2 finished with values: [0.3375816345214844, 0.9020656676982863] and parameters: {'learning_rate': 6.657366287711563e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 16, 'weight_decay': 0.0012099132058381746}. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a new besttrial 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "fixed params: [('num_train_epochs', 3), ('per_device_train_batch_size', 16)]\n",
            "objectives: ['eval_loss', 'eval_f1'], directions: [<StudyDirection.MINIMIZE: 1>, <StudyDirection.MAXIMIZE: 2>], warmup=345.0, min_trials=7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1734' max='1734' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1734/1734 31:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Mcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.044400</td>\n",
              "      <td>0.477999</td>\n",
              "      <td>0.857004</td>\n",
              "      <td>0.849846</td>\n",
              "      <td>0.861881</td>\n",
              "      <td>0.848858</td>\n",
              "      <td>0.836838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.462600</td>\n",
              "      <td>0.387921</td>\n",
              "      <td>0.870623</td>\n",
              "      <td>0.869135</td>\n",
              "      <td>0.869525</td>\n",
              "      <td>0.872959</td>\n",
              "      <td>0.852433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.419000</td>\n",
              "      <td>0.400260</td>\n",
              "      <td>0.870623</td>\n",
              "      <td>0.864652</td>\n",
              "      <td>0.868318</td>\n",
              "      <td>0.876437</td>\n",
              "      <td>0.853400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.370200</td>\n",
              "      <td>0.418430</td>\n",
              "      <td>0.872568</td>\n",
              "      <td>0.871944</td>\n",
              "      <td>0.883140</td>\n",
              "      <td>0.874731</td>\n",
              "      <td>0.856212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.382500</td>\n",
              "      <td>0.324070</td>\n",
              "      <td>0.903696</td>\n",
              "      <td>0.902675</td>\n",
              "      <td>0.907691</td>\n",
              "      <td>0.898722</td>\n",
              "      <td>0.889719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.213300</td>\n",
              "      <td>0.348456</td>\n",
              "      <td>0.895914</td>\n",
              "      <td>0.895949</td>\n",
              "      <td>0.899584</td>\n",
              "      <td>0.895676</td>\n",
              "      <td>0.881252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>805</td>\n",
              "      <td>0.209100</td>\n",
              "      <td>0.329644</td>\n",
              "      <td>0.897860</td>\n",
              "      <td>0.894247</td>\n",
              "      <td>0.894444</td>\n",
              "      <td>0.896377</td>\n",
              "      <td>0.883204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.216700</td>\n",
              "      <td>0.358480</td>\n",
              "      <td>0.896887</td>\n",
              "      <td>0.895374</td>\n",
              "      <td>0.908268</td>\n",
              "      <td>0.889416</td>\n",
              "      <td>0.882650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1035</td>\n",
              "      <td>0.209000</td>\n",
              "      <td>0.347998</td>\n",
              "      <td>0.898833</td>\n",
              "      <td>0.895017</td>\n",
              "      <td>0.896153</td>\n",
              "      <td>0.898837</td>\n",
              "      <td>0.884561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.244500</td>\n",
              "      <td>0.312597</td>\n",
              "      <td>0.911479</td>\n",
              "      <td>0.911428</td>\n",
              "      <td>0.911844</td>\n",
              "      <td>0.911582</td>\n",
              "      <td>0.898648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1265</td>\n",
              "      <td>0.119200</td>\n",
              "      <td>0.339444</td>\n",
              "      <td>0.907588</td>\n",
              "      <td>0.906186</td>\n",
              "      <td>0.908453</td>\n",
              "      <td>0.905227</td>\n",
              "      <td>0.894255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.099000</td>\n",
              "      <td>0.351310</td>\n",
              "      <td>0.909533</td>\n",
              "      <td>0.907805</td>\n",
              "      <td>0.905361</td>\n",
              "      <td>0.910826</td>\n",
              "      <td>0.896452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1495</td>\n",
              "      <td>0.120100</td>\n",
              "      <td>0.376423</td>\n",
              "      <td>0.906615</td>\n",
              "      <td>0.904627</td>\n",
              "      <td>0.904924</td>\n",
              "      <td>0.905400</td>\n",
              "      <td>0.893069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.094100</td>\n",
              "      <td>0.382670</td>\n",
              "      <td>0.905642</td>\n",
              "      <td>0.902575</td>\n",
              "      <td>0.904082</td>\n",
              "      <td>0.902797</td>\n",
              "      <td>0.891984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>0.093600</td>\n",
              "      <td>0.382177</td>\n",
              "      <td>0.908560</td>\n",
              "      <td>0.905748</td>\n",
              "      <td>0.907125</td>\n",
              "      <td>0.905637</td>\n",
              "      <td>0.895305</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-09 15:45:28,835]\u001b[0m Trial 3 finished with values: [0.31259655952453613, 0.9114277939920671] and parameters: {'learning_rate': 2.5148927786021194e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.0018156530773452493}. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a new besttrial 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "fixed params: [('num_train_epochs', 3), ('per_device_train_batch_size', 16)]\n",
            "objectives: ['eval_loss', 'eval_f1'], directions: [<StudyDirection.MINIMIZE: 1>, <StudyDirection.MAXIMIZE: 2>], warmup=345.0, min_trials=7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1734' max='1734' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1734/1734 31:42, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Mcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.826900</td>\n",
              "      <td>0.507011</td>\n",
              "      <td>0.840467</td>\n",
              "      <td>0.843160</td>\n",
              "      <td>0.839377</td>\n",
              "      <td>0.855670</td>\n",
              "      <td>0.819038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.511000</td>\n",
              "      <td>0.465518</td>\n",
              "      <td>0.859922</td>\n",
              "      <td>0.858179</td>\n",
              "      <td>0.859111</td>\n",
              "      <td>0.868707</td>\n",
              "      <td>0.841259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.451200</td>\n",
              "      <td>0.468440</td>\n",
              "      <td>0.860895</td>\n",
              "      <td>0.856261</td>\n",
              "      <td>0.854231</td>\n",
              "      <td>0.869166</td>\n",
              "      <td>0.842410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.428800</td>\n",
              "      <td>0.458320</td>\n",
              "      <td>0.854086</td>\n",
              "      <td>0.847473</td>\n",
              "      <td>0.852848</td>\n",
              "      <td>0.852775</td>\n",
              "      <td>0.834543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.446600</td>\n",
              "      <td>0.359926</td>\n",
              "      <td>0.883268</td>\n",
              "      <td>0.882475</td>\n",
              "      <td>0.884957</td>\n",
              "      <td>0.885909</td>\n",
              "      <td>0.867458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.244500</td>\n",
              "      <td>0.441770</td>\n",
              "      <td>0.879377</td>\n",
              "      <td>0.875918</td>\n",
              "      <td>0.885298</td>\n",
              "      <td>0.875331</td>\n",
              "      <td>0.863253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>805</td>\n",
              "      <td>0.241400</td>\n",
              "      <td>0.399898</td>\n",
              "      <td>0.896887</td>\n",
              "      <td>0.890433</td>\n",
              "      <td>0.884021</td>\n",
              "      <td>0.899641</td>\n",
              "      <td>0.882342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.261000</td>\n",
              "      <td>0.379392</td>\n",
              "      <td>0.892023</td>\n",
              "      <td>0.888796</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.883854</td>\n",
              "      <td>0.876447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1035</td>\n",
              "      <td>0.227800</td>\n",
              "      <td>0.364324</td>\n",
              "      <td>0.899805</td>\n",
              "      <td>0.898228</td>\n",
              "      <td>0.898876</td>\n",
              "      <td>0.898032</td>\n",
              "      <td>0.885273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.261700</td>\n",
              "      <td>0.374487</td>\n",
              "      <td>0.899805</td>\n",
              "      <td>0.898439</td>\n",
              "      <td>0.895813</td>\n",
              "      <td>0.902981</td>\n",
              "      <td>0.885512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1265</td>\n",
              "      <td>0.110000</td>\n",
              "      <td>0.435233</td>\n",
              "      <td>0.898833</td>\n",
              "      <td>0.894077</td>\n",
              "      <td>0.899405</td>\n",
              "      <td>0.892185</td>\n",
              "      <td>0.884421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.104200</td>\n",
              "      <td>0.424596</td>\n",
              "      <td>0.906615</td>\n",
              "      <td>0.901957</td>\n",
              "      <td>0.901102</td>\n",
              "      <td>0.903344</td>\n",
              "      <td>0.893084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1495</td>\n",
              "      <td>0.097800</td>\n",
              "      <td>0.436289</td>\n",
              "      <td>0.905642</td>\n",
              "      <td>0.901134</td>\n",
              "      <td>0.900715</td>\n",
              "      <td>0.902587</td>\n",
              "      <td>0.891982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.094100</td>\n",
              "      <td>0.434441</td>\n",
              "      <td>0.905642</td>\n",
              "      <td>0.899888</td>\n",
              "      <td>0.899473</td>\n",
              "      <td>0.901409</td>\n",
              "      <td>0.891961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>0.084000</td>\n",
              "      <td>0.436610</td>\n",
              "      <td>0.905642</td>\n",
              "      <td>0.899840</td>\n",
              "      <td>0.899405</td>\n",
              "      <td>0.901162</td>\n",
              "      <td>0.891978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-09 16:18:05,200]\u001b[0m Trial 4 finished with values: [0.3599255383014679, 0.8824751058105537] and parameters: {'learning_rate': 7.664911172180888e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.0011232522906387502}. \u001b[0m\n",
            "fixed params: [('num_train_epochs', 3), ('per_device_train_batch_size', 16)]\n",
            "objectives: ['eval_loss', 'eval_f1'], directions: [<StudyDirection.MINIMIZE: 1>, <StudyDirection.MAXIMIZE: 2>], warmup=345.0, min_trials=7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='811' max='1734' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 811/1734 14:47 < 16:52, 0.91 it/s, Epoch 1.40/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Mcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.138400</td>\n",
              "      <td>0.510751</td>\n",
              "      <td>0.858949</td>\n",
              "      <td>0.850783</td>\n",
              "      <td>0.865221</td>\n",
              "      <td>0.845530</td>\n",
              "      <td>0.838606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.493400</td>\n",
              "      <td>0.403923</td>\n",
              "      <td>0.871595</td>\n",
              "      <td>0.871239</td>\n",
              "      <td>0.875081</td>\n",
              "      <td>0.871106</td>\n",
              "      <td>0.853473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.427500</td>\n",
              "      <td>0.400283</td>\n",
              "      <td>0.879377</td>\n",
              "      <td>0.873547</td>\n",
              "      <td>0.876968</td>\n",
              "      <td>0.881498</td>\n",
              "      <td>0.862976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.376300</td>\n",
              "      <td>0.422539</td>\n",
              "      <td>0.866732</td>\n",
              "      <td>0.867527</td>\n",
              "      <td>0.877773</td>\n",
              "      <td>0.871572</td>\n",
              "      <td>0.849942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.382600</td>\n",
              "      <td>0.326713</td>\n",
              "      <td>0.901751</td>\n",
              "      <td>0.898197</td>\n",
              "      <td>0.903550</td>\n",
              "      <td>0.893859</td>\n",
              "      <td>0.887436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.234600</td>\n",
              "      <td>0.348992</td>\n",
              "      <td>0.896887</td>\n",
              "      <td>0.895712</td>\n",
              "      <td>0.900723</td>\n",
              "      <td>0.893602</td>\n",
              "      <td>0.882282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>805</td>\n",
              "      <td>0.221000</td>\n",
              "      <td>0.323622</td>\n",
              "      <td>0.902724</td>\n",
              "      <td>0.900304</td>\n",
              "      <td>0.902369</td>\n",
              "      <td>0.899446</td>\n",
              "      <td>0.888599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "db_path = \"/content/gdrive/My Drive/Colab Notebooks/nlp-classification/\"\n",
        "db_name = \"10kgnad_optuna\"\n",
        "# study_name = checkpoint + \"_multi_epoch234\"\n",
        "# study_name = checkpoint + \"_loss-f1_bs32_epoch23\"\n",
        "study_name = checkpoint + \"_loss-f1_bs16_epoch23\"\n",
        "\n",
        "# multi objective study\n",
        "# https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/002_multi_objective.html#sphx-glr-tutorial-20-recipes-002-multi-objective-py\n",
        "study = optuna.create_study(study_name=study_name,\n",
        "                            directions=[\"minimize\", \"maximize\"],\n",
        "                            storage=f\"sqlite:///{db_path}{db_name}.db\",\n",
        "                            load_if_exists=True,)\n",
        "\n",
        "# give some hyperparameters that are presumably good\n",
        "# study.enqueue_trial(\n",
        "#     {\n",
        "#         \"learning_rate\": 8e-5,\n",
        "#         \"weight_decay\": 1e-3,\n",
        "#     }\n",
        "# )\n",
        "\n",
        "# https://stackoverflow.com/questions/59129812/how-to-avoid-cuda-out-of-memory-in-pytorch\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "study.optimize(objective, n_trials=100, callbacks=[best_model_callback])\n",
        "\n",
        "# study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaHTHuP9W6Dn"
      },
      "outputs": [],
      "source": [
        "!ls -lahtr 10kgnad_hf__distilbert-base-german-cased/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBZsS24YbFpy"
      },
      "source": [
        "## Hyperparameter Tuning\n",
        "\n",
        "https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.hyperparameter_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phuJdMD6aaLP"
      },
      "outputs": [],
      "source": [
        "# disable transformer warnings like \"Some weights of the model checkpoint ...\"\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=str(project_name),\n",
        "    report_to=[],\n",
        "    log_level=\"error\",\n",
        "    disable_tqdm=False,\n",
        "\n",
        "    evaluation_strategy=\"steps\",\n",
        "    # eval_steps=eval_steps,\n",
        "    save_strategy=\"steps\",\n",
        "    # save_steps=eval_steps,\n",
        "    # load_best_model_at_end=False,\n",
        "    # metric_for_best_model=\"eval_loss\",\n",
        "    # greater_is_better=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_gnad10k[\"train\"],\n",
        "    eval_dataset=tokenized_gnad10k[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "# Default objective is the sum of all metrics\n",
        "# when metrics are provided, so we have to maximize it.\n",
        "# best = trainer.hyperparameter_search(\n",
        "#     hp_space=hp_space,\n",
        "#     compute_objective=objective,\n",
        "#     n_trials=2\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "21c_10kGNAD_huggingface_basic_optuna.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCO9YrNMVd2AL2aP9mWtW1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "355a2b3420774838b9361b490ad4c958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f4acce1e6f442e9930eef396b00aedd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_753b7b3f9ef045488e90aef50eee4b42",
              "IPY_MODEL_65b73b2ae1a44b3e87bef25762dae19c",
              "IPY_MODEL_01581091bb0f437a9592d1841beea701"
            ]
          }
        },
        "8f4acce1e6f442e9930eef396b00aedd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "753b7b3f9ef045488e90aef50eee4b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db34d57214034bdb8687b232089d840c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f8d0ce4d4fb4c09bfeb11f2cab4fd4b"
          }
        },
        "65b73b2ae1a44b3e87bef25762dae19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7cae5fdfa9924e77a7d59576e78415f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff32d8c622774e538ee8bdadf3393093"
          }
        },
        "01581091bb0f437a9592d1841beea701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98e188919de44a2e85f0004010ebee49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00, 40.20it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c6ba294e8dd41ab9614971767b4be1d"
          }
        },
        "db34d57214034bdb8687b232089d840c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f8d0ce4d4fb4c09bfeb11f2cab4fd4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cae5fdfa9924e77a7d59576e78415f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff32d8c622774e538ee8bdadf3393093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98e188919de44a2e85f0004010ebee49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c6ba294e8dd41ab9614971767b4be1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a7a62e38a414f93a0bc606ffb332598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_17c6e3596d7540c293dc1bec00e7fdc5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_768ce8b64cc64e03935427b8154336ea",
              "IPY_MODEL_ab57ee6611f3437ea441244f126d5e95",
              "IPY_MODEL_ebfd5be419bf475482d88259eee4f02f"
            ]
          }
        },
        "17c6e3596d7540c293dc1bec00e7fdc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "768ce8b64cc64e03935427b8154336ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9efe16d403d34e788ac4d944eca683f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_793864aaa59243848602d2fbbd0c3ffb"
          }
        },
        "ab57ee6611f3437ea441244f126d5e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f01a034dd014421da2b6d8cf9997f15a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d71c4c42b297483fb225519681386452"
          }
        },
        "ebfd5be419bf475482d88259eee4f02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c3f043d41fe48feb784ed760b2f32c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:01&lt;00:00,  1.22s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a8bb998beae4c3f906ed3c35ac57b6d"
          }
        },
        "9efe16d403d34e788ac4d944eca683f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "793864aaa59243848602d2fbbd0c3ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f01a034dd014421da2b6d8cf9997f15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d71c4c42b297483fb225519681386452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c3f043d41fe48feb784ed760b2f32c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a8bb998beae4c3f906ed3c35ac57b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}