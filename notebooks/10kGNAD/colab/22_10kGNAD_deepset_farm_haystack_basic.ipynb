{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "22_10kGNAD_deepset-farm-haystack_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNp97Cv+hLfoWtEHuQz+QDQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goerlitz/nlp-classification/blob/main/notebooks/10kGNAD/colab/22_10kGNAD_deepset_farm_haystack_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ei_ToiRvHiO"
      },
      "source": [
        "# Classifying German News Articles with deepset's Farm/Haystack\n",
        "\n",
        "NOTE: [deepset's Farm](https://github.com/deepset-ai/farm/) is now part of [deepset's Haystack](https://github.com/deepset-ai/haystack/). Still, the Farm documentation is helpful for classification implementation as haystack focuses on question answering.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "1. Train a text classifier with transfer learning based on a pretrained German transformer model.\n",
        "2. Simplify implementation by using [deepset's Farm](https://github.com/deepset-ai/FARM) library.\n",
        "\n",
        "based on https://towardsdatascience.com/fine-tuning-bert-for-text-classification-with-farm-2880665065e2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L01RmQaogkV"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMBjnHS8okJP"
      },
      "source": [
        "checkpoint = \"distilbert-base-german-cased\"\n",
        "\n",
        "# checkpoint = \"deepset/gbert-base\"\n",
        "\n",
        "# checkpoint = \"deepset/gelectra-base\"\n",
        "\n",
        "project_name = \"10kgnad_huggingface__\" + checkpoint.replace(\"/\", \"_\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihLF5YTqtQxz",
        "outputId": "eaae72f3-d749-4d2c-e83b-b059c9538ed2"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 28 15:20:02 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2lYW5A2o4z9"
      },
      "source": [
        "## Install and Configure Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36FFKPYhzDtG",
        "outputId": "ff74a6b3-254a-46d9-d99e-44bee3f450e8"
      },
      "source": [
        "%%time\n",
        "# ensure the right torch versions (https://pytorch.org/get-started/previous-versions/)\n",
        "!pip install -q --upgrade torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 >/dev/null\n",
        "!pip install -q --upgrade farm-haystack >/dev/null\n",
        "\n",
        "# check installed version\n",
        "!pip freeze | grep transformers\n",
        "!pip freeze | grep farm\n",
        "!pip freeze | grep torch\n",
        "# transformers==4.6.1\n",
        "# farm==0.8.0\n",
        "# farm-haystack==0.10.0\n",
        "# torch==1.7.1\n",
        "# torchaudio==0.7.2\n",
        "# torchsummary==1.5.1\n",
        "# torchtext==0.8.1\n",
        "# torchvision==0.8.2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence-transformers==2.1.0\n",
            "transformers==4.6.1\n",
            "farm==0.8.0\n",
            "farm-haystack==0.10.0\n",
            "torch==1.7.1\n",
            "torchaudio==0.7.2\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.8.1\n",
            "torchvision==0.8.2\n",
            "CPU times: user 71.8 ms, sys: 38.8 ms, total: 111 ms\n",
            "Wall time: 9.71 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8cU2PM9ETJx"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKUqNAfZo9E5"
      },
      "source": [
        "## Fetch Data\n",
        "\n",
        "Download [10k German News Articles Dataset](https://tblock.github.io/10kGNAD/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEcaedwWD66N",
        "outputId": "467c1411-1365-483f-f26b-34779a93023f"
      },
      "source": [
        "%env DIR=data\n",
        "\n",
        "!mkdir -p $DIR\n",
        "!wget -nc https://github.com/tblock/10kGNAD/blob/master/train.csv?raw=true -nv -O $DIR/train.csv\n",
        "!wget -nc https://github.com/tblock/10kGNAD/blob/master/test.csv?raw=true -nv -O $DIR/test.csv\n",
        "!ls -lAh $DIR | cut -d \" \" -f 5-"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: DIR=data\n",
            "\n",
            "2.7M Nov 28 14:14 test2.csv\n",
            "2.7M Nov 28 12:56 test.csv\n",
            " 24M Nov 28 14:14 train2.csv\n",
            " 24M Nov 28 12:56 train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuLSIj9NkXAG"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL2RFkuaaQug"
      },
      "source": [
        "data_dir = Path(os.getenv(\"DIR\"))\n",
        "\n",
        "train_file = data_dir / 'train.csv'\n",
        "test_file = data_dir / 'test.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8uT0utXQitf"
      },
      "source": [
        "def load_file(filepath: Path) -> pd.DataFrame:\n",
        "    f = pd.read_csv(filepath, sep=\";\", quotechar=\"'\", names=['labels', 'text'])\n",
        "    return f"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "pFMweinxRnAT",
        "outputId": "f9e84b85-da45-4945-97d0-6b98dabad737"
      },
      "source": [
        "train_df = load_file(data_dir / 'train.csv')\n",
        "train_df.to_csv(data_dir / 'train2.csv')\n",
        "print(f\"{train_df.shape[0]:,} articles\")\n",
        "display(train_df.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9,245 articles\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sport</td>\n",
              "      <td>21-Jähriger fällt wohl bis Saisonende aus. Wie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kultur</td>\n",
              "      <td>Erfundene Bilder zu Filmen, die als verloren g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Web</td>\n",
              "      <td>Der frischgekürte CEO Sundar Pichai setzt auf ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Putin: \"Einigung, dass wir Menge auf Niveau vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Inland</td>\n",
              "      <td>Estland sieht den künftigen österreichischen P...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       labels                                               text\n",
              "0       Sport  21-Jähriger fällt wohl bis Saisonende aus. Wie...\n",
              "1      Kultur  Erfundene Bilder zu Filmen, die als verloren g...\n",
              "2         Web  Der frischgekürte CEO Sundar Pichai setzt auf ...\n",
              "3  Wirtschaft  Putin: \"Einigung, dass wir Menge auf Niveau vo...\n",
              "4      Inland  Estland sieht den künftigen österreichischen P..."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "l5Vx3IriIYPK",
        "outputId": "658f7b9f-0a7c-4b97-cb0b-c39c7cb632a2"
      },
      "source": [
        "test_df = load_file(data_dir / 'test.csv')\n",
        "test_df.to_csv(data_dir / 'test2.csv')\n",
        "print(f\"{test_df.shape[0]:,} articles\")\n",
        "display(test_df.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,028 articles\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Die Gewerkschaft GPA-djp lanciert den \"All-in-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sport</td>\n",
              "      <td>Franzosen verteidigen 2:1-Führung – Kritische ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Web</td>\n",
              "      <td>Neues Video von Designern macht im Netz die Ru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sport</td>\n",
              "      <td>23-jähriger Brasilianer muss vier Spiele pausi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>International</td>\n",
              "      <td>Aufständische verwendeten Chemikalie bei Gefec...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          labels                                               text\n",
              "0     Wirtschaft  Die Gewerkschaft GPA-djp lanciert den \"All-in-...\n",
              "1          Sport  Franzosen verteidigen 2:1-Führung – Kritische ...\n",
              "2            Web  Neues Video von Designern macht im Netz die Ru...\n",
              "3          Sport  23-jähriger Brasilianer muss vier Spiele pausi...\n",
              "4  International  Aufständische verwendeten Chemikalie bei Gefec..."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmAiISLJIQuL"
      },
      "source": [
        "## Experiment Logging Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRdmk46kIUV5",
        "outputId": "f93dcae4-6fa4-4b47-f262-ec82b67beff8"
      },
      "source": [
        "from farm.utils import MLFlowLogger\n",
        "\n",
        "ml_logger = MLFlowLogger(tracking_uri=\"https://public-mlflow.deepset.ai/\")\n",
        "ml_logger.init_experiment(experiment_name=\"10kGNAD\", run_name=\"10kGNAD\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " __          __  _                            _        \n",
            " \\ \\        / / | |                          | |       \n",
            "  \\ \\  /\\  / /__| | ___ ___  _ __ ___   ___  | |_ ___  \n",
            "   \\ \\/  \\/ / _ \\ |/ __/ _ \\| '_ ` _ \\ / _ \\ | __/ _ \\ \n",
            "    \\  /\\  /  __/ | (_| (_) | | | | | |  __/ | || (_) |\n",
            "     \\/  \\/ \\___|_|\\___\\___/|_| |_| |_|\\___|  \\__\\___/ \n",
            "  ______      _____  __  __  \n",
            " |  ____/\\   |  __ \\|  \\/  |              _.-^-._    .--.\n",
            " | |__ /  \\  | |__) | \\  / |           .-'   _   '-. |__|\n",
            " |  __/ /\\ \\ |  _  /| |\\/| |          /     |_|     \\|  |\n",
            " | | / ____ \\| | \\ \\| |  | |         /               \\  |\n",
            " |_|/_/    \\_\\_|  \\_\\_|  |_|        /|     _____     |\\ |\n",
            "                                     |    |==|==|    |  |\n",
            "|---||---|---|---|---|---|---|---|---|    |--|--|    |  |\n",
            "|---||---|---|---|---|---|---|---|---|    |==|==|    |  |\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARWnT7ZWrhux"
      },
      "source": [
        "## Training Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntU6DQIrkeO"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl9aNAY71Eb8",
        "outputId": "e33e680c-25cd-4d23-eb17-fe06321a1487"
      },
      "source": [
        "# need to load transformer tokenizer first - FARM cannot infer lower case setting (it seems)\n",
        "do_lower_case = AutoTokenizer.from_pretrained(checkpoint).do_lower_case\n",
        "tokenizer = Tokenizer.load(checkpoint, do_lower_case=do_lower_case)\n",
        "tokenizer"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11/28/2021 15:20:20 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'DistilBertTokenizer'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='distilbert-base-german-cased', vocab_size=31102, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5jdOeOFtko3",
        "outputId": "8b09d864-9a32-4c3a-ebb2-7e057996cd52"
      },
      "source": [
        "label_list = list(train_df.labels.unique())\n",
        "eval_metrics = \"f1_macro\" # desired metrics for evaluation\n",
        "\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                        max_seq_len=tokenizer.model_max_length,\n",
        "                                        data_dir='data',\n",
        "                                        train_filename=\"train2.csv\",\n",
        "                                        dev_filename=None,\n",
        "                                        test_filename=\"test2.csv\",\n",
        "                                        quote_char='\"',\n",
        "                                        delimiter=\",\",\n",
        "                                        label_column_name=\"labels\",\n",
        "                                        label_list=label_list,\n",
        "                                        metric=eval_metrics\n",
        "                                        # multilabel=True,\n",
        "                                        # dev_split=0.1 # this will extract 10% of the train set to create a dev set\n",
        "                                        )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11/28/2021 15:20:21 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jON9TIbO0kqh",
        "outputId": "034f8217-2cfc-40ac-fe8c-813c0074beed"
      },
      "source": [
        "batch_size = 8 # larger batch sizes might use too much computing power in Colab\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11/28/2021 15:20:22 - INFO - farm.data_handler.data_silo -   \n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|       \n",
            " (o)(o)------'\\ _ /     ( )      \n",
            " \n",
            "11/28/2021 15:20:22 - INFO - farm.data_handler.data_silo -   LOADING TRAIN DATA\n",
            "11/28/2021 15:20:22 - INFO - farm.data_handler.data_silo -   ==================\n",
            "11/28/2021 15:20:22 - INFO - farm.data_handler.data_silo -   Loading train set from: data/train2.csv \n",
            "11/28/2021 15:20:22 - INFO - farm.data_handler.data_silo -   Got ya 2 parallel workers to convert 9245 dictionaries to pytorch datasets (chunksize = 925)...\n",
            "11/28/2021 15:20:22 - INFO - farm.data_handler.data_silo -    0    0 \n",
            "11/28/2021 15:20:22 - INFO - farm.data_handler.data_silo -   /|\\  /w\\\n",
            "11/28/2021 15:20:22 - INFO - farm.data_handler.data_silo -   /'\\  /'\\\n",
            "11/28/2021 15:20:22 - INFO - farm.data_handler.data_silo -     \n",
            "Preprocessing Dataset data/train2.csv:   0%|          | 0/9245 [00:00<?, ? Dicts/s]11/28/2021 15:20:24 - INFO - farm.data_handler.processor -   *** Show 1 random examples ***\n",
            "11/28/2021 15:20:24 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: None\n",
            "Clear Text: \n",
            " \ttext_classification_label: Web\n",
            " \ttext: Japanischer Konzern übernimmt laut Insider Entwicklungskosten für Hersteller Ubisoft. Die Fortsetzung zu Ubisofts viel gelobten, aber kommerziell nicht erfolgreichen Abenteuer Beyond Good & Evil blickt auf eine langjährige und turbulente Entwicklungsgeschichte zurück. Wie die Seite Destructoid nun von Insidern erfahren haben will, soll Projekt kürzlich eine neue Finanzspritze erhalten haben. Und zwar von Nintendo. Demzufolge werde der japanische Hersteller die Fertigstellungskosten übernehmen und dafür das Spiel exklusiv für die kommende Konsole NX herausbringen. Ein Deal, wie er schon beim Kampfspiel Bayonetta 2 mit Platinum Games eingegangen wurde. Die Informationen stammen vom Brancheninsider Geno, der ein ausführliches Dokument zu dem Spiel an die Medien weitergeleitet hat. Geno berichtete zuvor bereits korrekt über bis dahin nicht angekündigte Pokémon-Inhalte sowie Microsofts IllumiRoom-Projekt. Den von zwei weiteren Quellen Destructoids bestätigten Unterlagen zufolge soll der BG&E-Nachfolger den Arbeitstitel Beyond Good and Evil: The Prejudices of Philosophers tragen und 2017 in den Handel kommen. Weder Ubisoft noch Nintendo haben sich zu den Berichten geäußert.\n",
            "Tokenized: \n",
            " \tNone\n",
            "Features: \n",
            " \tinput_ids: [102, 4664, 689, 8448, 10242, 3251, 2928, 2094, 5323, 4100, 231, 6646, 218, 5871, 25602, 566, 229, 14103, 205, 218, 5871, 25602, 30886, 827, 17795, 6636, 818, 494, 11506, 137, 255, 11048, 13221, 398, 18026, 30888, 17361, 1562, 12145, 221, 21396, 216, 261, 17399, 136, 24599, 7890, 5622, 5323, 4446, 876, 566, 755, 128, 1640, 19265, 344, 1782, 19100, 1269, 195, 2928, 2094, 30882, 5119, 450, 978, 818, 585, 2331, 11898, 261, 1133, 1907, 26494, 524, 1957, 450, 566, 700, 2296, 195, 17265, 1583, 3847, 566, 1859, 30156, 1767, 125, 17111, 6646, 128, 15824, 16547, 6845, 136, 1877, 199, 845, 18563, 433, 231, 128, 17187, 30113, 30881, 196, 30975, 2095, 4019, 566, 311, 18045, 818, 335, 180, 778, 916, 3639, 854, 2049, 1820, 25740, 197, 212, 18019, 113, 182, 13666, 15483, 325, 566, 229, 2172, 5593, 507, 12527, 2234, 2094, 1017, 30892, 818, 125, 143, 30546, 30886, 5517, 205, 249, 845, 208, 128, 3562, 576, 9724, 308, 566, 1017, 30892, 7333, 3489, 1058, 19472, 304, 378, 6166, 255, 10627, 30881, 28547, 30969, 4426, 232, 11154, 686, 15232, 30886, 8250, 30620, 8981, 192, 232, 2331, 566, 2025, 195, 510, 2642, 7143, 19265, 344, 1782, 19100, 30886, 11878, 30882, 13227, 5925, 585, 125, 142, 30917, 1562, 149, 232, 5394, 190, 1293, 6242, 398, 18026, 30888, 17361, 1257, 12145, 221, 853, 996, 4580, 5192, 1511, 4743, 917, 7328, 462, 4542, 136, 2390, 153, 190, 4856, 1263, 566, 25459, 218, 5871, 25602, 447, 17265, 1583, 3847, 450, 251, 205, 190, 18762, 18381, 566, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [2]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset data/train2.csv: 100%|██████████| 9245/9245 [00:10<00:00, 850.24 Dicts/s] \n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   \n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   LOADING DEV DATA\n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   =================\n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   Loading dev set as a slice of train set\n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   Took 1845 samples out of train set to create dev set (dev split is roughly 0.1)\n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   \n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   LOADING TEST DATA\n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   =================\n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   Loading test set from: data/test2.csv\n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   Got ya 2 parallel workers to convert 1028 dictionaries to pytorch datasets (chunksize = 103)...\n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -    0    0 \n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   /w\\  /w\\\n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -   / \\  / \\\n",
            "11/28/2021 15:20:33 - INFO - farm.data_handler.data_silo -     \n",
            "Preprocessing Dataset data/test2.csv:   0%|          | 0/1028 [00:00<?, ? Dicts/s]11/28/2021 15:20:34 - INFO - farm.data_handler.processor -   *** Show 1 random examples ***\n",
            "11/28/2021 15:20:34 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: None\n",
            "Clear Text: \n",
            " \ttext_classification_label: Panorama\n",
            " \ttext: Thorbjørn Jagland über die Flüchtlingskrise, die europäische Art Menschen aufzunehmen und warum er der EU noch einmal den Friedensnobelpreis geben würde. Standard: Kann Europa den Flüchtlingsstrom im Moment bewältigen und die Menschen integrieren? Jagland: Absolut. Natürlich ist die kurze Zeit, in der das passiert und die Art, wie die Menschen Europa erreichen, eine Herausforderung. Aber erinnern wir uns an die Situation von 1956 als 200.000 Menschen binnen weniger Stunden Ungarn Richtung Österreich verlassen haben. In ein paar Wochen waren diese Flüchtlinge in Österreich aber auch in anderen europäischen Ländern untergebracht. Es kann bewältigt werden. Es ist eine Frage des Willens, der Organisation und finanzieller Kraft. Der Kontinent ist reicher als je zuvor, deshalb sollte man auch mit dieser Situation umgehen können. Ich verstehe nicht, wie die Aufteilung der Flüchtlinge jetzt zu so einem großen Problem werden konnte. Standard: Hat der fehlende Wille im Moment auch etwas damit zu tun, dass die Flüchtlinge nun aus einem anderen Kulturkreis als damals die Ungarn stammen? Jagland: Diese Ängste gibt es seit langer Zeit in Europa. Aber da muss politische Führungsstärke ins Spiel kommen. Politiker dürfen nicht mit solchen Ängsten spielen, sondern müssen den Menschen die Situation erklären und sie informieren. Ausländer sind keine Gefahr für Europa. Wir brauchen sie. Mittelfristig gesehen, braucht Europa mehr Leute, weil unsere eigene Gesellschaft altert. Um den Wohlstand zu erhalten, brauchen wir mehr Menschen am Arbeitsmarkt. Die Angst vor Terrorismus kann ich verstehen aber nichtsdestotrotz muss man diese Situation nun schaffen. Standard: Wie sollte etwa Ungarn mit den Flüchtlingen im Land umgehen? Jagland: Ich erwarte mir, dass sich jede europäische Nation an ein Grundprinzip hält: In dem Moment, in dem eine Person ihren Fuß auf europäischen Boden setzt, steht sie unter dem Schutz der Europäischen Menschenrechtskonvention. Deshalb sollte jede Person nach diesem Prinzip und der Rechtsprechung des Gerichts in Straßburg behandelt werden. Es gibt Grundsätze, wie mit diesen Menschen umgegangen werden soll. So haben sie etwa das Recht, dass ihr Fall angehört und bearbeitet wird. Ebenso gibt es Standards, wie Flüchtlinge in Gewahrsam oder Auffanglagern umgegangen werden soll: Zugang zu Nahrung, Unterkünfte und medizinischer Versorgung sind essentiell. Das ist die europäische Art, Menschen aufzunehmen. Das bedeutet nicht, dass jeder das Recht auf Asyl hat. Aber sie haben zumindest das Recht ihren Fall und ihren Asylantrag einzubringen. Standard: Offensichtlich hält sich Ungarn nicht an diese Standards. Wie kann die Europäische Union reagieren, um auf die ungarische Regierung Druck auszuüben? Jagland: Es gab bereits Reaktion auf diese spezielle Situation. Der Europarat hat die ungarische Regierung an ihre Verpflichtung im Sinne der Menschenrechtskonvention und die zuvor genannten Grundstandards erinnert. Ich glaube, dass das, was jetzt geschieht – der freie Weg nach Österreich und Deutschland – aufgrund des Drucks, der auf Ungarn ausgeübt wurde, geschehen ist. Standard: Wie schätzen Sie die Reaktion von Österreich im Moment ein? Jagland: Ich kann mich nicht beschweren, wie Österreich auf die Situation reagiert. Standard: Gestern trafen Sie den UN-Hochkommissar für Flüchtlinge, António Guterres, in Genf. Worauf haben sich Europarat und UNHCR geeinigt? Jagland: Wir waren uns einig, dass es einen klaren Bedarf an europäischer Solidarität gibt – wenn es um die Aufteilung von Flüchtlingen geht. Dass man viel bessere Aufnahmezentren an den Außengrenzen braucht – wenn es um die Effektivität der Registrierungen geht. Wer diese Zentren schlussendlich betreibt, obliegt den Schengen-Ländern. Aber ich kann mir vorstellen, dass man die auch gemeinsam betreiben kann. Außerdem brauchen wir solide Standards für diese Aufnahmezentren. Und es braucht finanzielle Hilfen für die UNHCR-Einsätze vor Ort. Guterres hat mich gestern informiert, dass das von UNHCR-Regionalprogramm für Syrien nur zu 20 Prozent finanziert ist. Die europäischen Länder sollten vielmehr unterstützen, was die Vereinten Nationen in den Ländern rund um die Krisengebiete für Flüchtlinge leisten. Standard: Freiwillige aus Europa helfen in Griechenland oder Italien. Menschen in Ungarn, Österreich oder Deutschland begrüßen Flüchtlinge und unterstützen sie. Ist die Gesellschaft weiter als ihre politischen Führer? Jagland: Es ist ermutigend zu sehen, wie die Zivilgesellschaft auf die Flüchtlinge reagiert. Diese Mensch-zu-Mensch-Solidarität sollte sich auf eine Staaten-zu-Staaten-Solidarität übertragen. Die Politiker sollten jetzt davon profitieren und sie nutzen, um politische Führungskraft zu zeigen. Die Bilder, die uns im Moment erreichen, haben eine ähnliche Auswirkung wie die Bilder damals während des Balkankonflikts. Als die Bilder des zerbombten Sarajevo um die Welt gingen, änderten die Länder ihre passive Haltung hin zu einer Solidarität. Die öffentliche Meinung spielt im Moment eine starke und positive Rolle. Standard: Sie waren Premierminister von Norwegen, das Millionen in die Hilfe vor Ort investiert und in der Region Projekte unterstützt. Trotzdem nimmt das Land selbst wenige Flüchtlinge auf. Rechtfertigt das eine Engagement das fehlende andere? Jagland: Nein, das rechtfertigt nicht, dass man zögert, Flüchtlinge aufzunehmen. Ich habe den Norwegern gesagt: Wenn die Aufnahme von 8.000 Menschen so große politische Probleme in einem der reichsten Länder Europas auslöst, könnt ihr euch vorstellen, was 1,5 Millionen Menschen in der Türkei für eine Auswirkung haben. Wir sollten uns solidarisch zeigen. Mir kommt es vor, dass je reicher man wird, umso weniger ist man bereit, Solidarität zu zeigen. Aber das ändert sich nun. In Norwegen aber auch zum Beispiel in Großbritannien, wo Premier David Cameron seine Position ein wenig geändert hat. Die Dinge ändern sich zum Besseren. Standard: Würden Sie der Europäischen Union noch einmal den Friedensnobelpreis verleihen? Jagland: Ja, das war die absolut richtige Entscheidung. Aufgrund der Geschichte. Wir zeichnen niemand für seine künftigen Leistungen aus, sondern für bereits Geleistetes. Die Europäische Union hat so viel zur Versöhnung der Länder dieses Kontinents beigetragen. Ich glaube noch immer, dass es ohne die Europäische Union und ihrer Struktur und Institution noch schwerer wäre, diese Krise zu meistern. Standard: Vor zwei Jahren haben sie im STANDARD-Interview gesagt, dass wir uns erst am Anfang einer Flüchtlingskrise befinden. Wo stehen wir nun? Jagland: Wir befinden uns mittendrin und sehen kein Ende. Das liegt an der chaotischen Situation in Ländern wie Syrien, Libyen oder Nordafrika. Ich sehe kein Licht am Ende des Tunnels. Keiner kann vorhersehen, wann der Krieg in Syrien vorbei sein wird. Die Lösung in Libyen ist nicht absehbar. Das wird noch lange dauern. Man kann hoffen, dass der Iran-Deal von Wien zu mehr Kooperation etwa im Zusammenhang mit Syrien führen kann. Man darf aber nicht nur darauf hoffen, wir müssen diese Kooperation einfordern. Die Vetomächte des UN-Sicherheitsrats haben eine große Verantwortung, was in diesen Regionen passiert ist aber auch aufgrund des Mandats, das sie von der Weltgemeinschaft bekommen haben. Sie sind für den Frieden und die Sicherheit der gesamten Welt verantwortlich. Das Problem ist aber, dass die Länder auf ihre eigenen Interessen schauen und das steht im Gegensatz zu ihrer Verantwortung. Das muss sich ändern, damit Krisen gelöst werden können. Ohne diesen gemeinsamen Standpunkt wird die weltweite Gewalt weitergehen. Und Flüchtlinge werden weiterhin nach Europa kommen.\n",
            "Tokenized: \n",
            " \tNone\n",
            "Features: \n",
            " \tinput_ids: [102, 14997, 30896, 30948, 31009, 3780, 19599, 492, 304, 128, 13802, 10984, 818, 128, 6086, 1622, 1021, 14400, 136, 4543, 180, 125, 1187, 447, 1839, 190, 10758, 2783, 2204, 3957, 2082, 1618, 566, 4737, 853, 5432, 1869, 190, 13802, 10164, 223, 4768, 20698, 136, 128, 1021, 23114, 1992, 19599, 492, 853, 13372, 211, 566, 5936, 215, 128, 7730, 577, 818, 153, 125, 199, 4519, 136, 128, 1622, 818, 335, 128, 1021, 1869, 3541, 818, 261, 10382, 566, 1124, 7973, 268, 734, 208, 128, 4084, 195, 9166, 276, 421, 566, 3080, 1021, 19219, 2303, 2932, 7601, 2749, 2486, 4569, 450, 566, 259, 143, 3506, 2168, 764, 687, 8709, 153, 2486, 494, 313, 153, 925, 3159, 2938, 11484, 566, 479, 530, 2470, 28804, 338, 566, 479, 215, 261, 2167, 222, 9203, 30886, 818, 125, 4879, 136, 24572, 2832, 566, 351, 19987, 215, 20367, 30884, 276, 729, 3489, 818, 3462, 1474, 545, 313, 212, 660, 4084, 17432, 618, 566, 395, 9622, 255, 818, 335, 128, 19157, 125, 8709, 1184, 205, 262, 403, 1793, 1550, 338, 1334, 566, 4737, 853, 6261, 125, 20662, 20950, 223, 4768, 313, 1247, 1039, 205, 1913, 818, 377, 128, 8709, 1269, 260, 403, 925, 2174, 1998, 276, 3192, 128, 7601, 5593, 1992, 19599, 492, 853, 1100, 27042, 241, 800, 288, 836, 11198, 577, 153, 1869, 566, 1124, 408, 1092, 4694, 9976, 14621, 762, 845, 1263, 566, 5433, 4156, 255, 212, 5748, 27042, 291, 3335, 818, 1427, 1128, 190, 1021, 128, 4084, 7431, 136, 307, 10952, 566, 14828, 341, 855, 5628, 231, 1869, 566, 505, 4604, 307, 566, 1369, 7736, 3271, 818, 5421, 1869, 484, 3091, 818, 1521, 2067, 3468, 3018, 9765, 30885, 566, 607, 190, 21720, 205, 1957, 818, 4604, 268, 484, 1021, 339, 8361, 566, 229, 4689, 334, 22268, 530, 383, 5704, 494, 1607, 4348, 27685, 19187, 1092, 545, 687, 4084, 1269, 4501, 566, 4737, 853, 755, 1474, 1096, 7601, 212, 190, 18552, 223, 571, 17432, 1992, 19599, 492, 853, 395, 26745, 780, 818, 377, 251, 4095, 6086, 12035, 208, 143, 926, 20119, 4172, 853, 259, 249, 4768, 818, 153, 249, 261, 1034, 1244, 1652, 216, 3159, 3140, 4646, 818, 1419, 307, 389, 249, 2708, 125, 1409, 16849, 29093, 566, 5081, 1474, 4095, 1034, 333, 893, 7227, 136, 125, 17161, 222, 3897, 153, 16531, 6955, 338, 566, 479, 800, 15790, 818, 335, 212, 1451, 1021, 9448, 1317, 338, 585, 566, 503, 450, 307, 1096, 199, 2514, 818, 377, 348, 1688, 24258, 136, 19016, 371, 566, 10244, 800, 288, 13599, 818, 335, 8709, 153, 1599, 238, 702, 394, 446, 1438, 24458, 9448, 1317, 338, 585, 853, 4477, 205, 13715, 818, 16317, 136, 14551, 30884, 10092, 341, 8030, 185, 630, 566, 347, 215, 128, 6086, 1622, 818, 1021, 14400, 566, 347, 3918, 255, 818, 377, 2422, 199, 2514, 216, 8168, 308, 566, 1124, 307, 450, 5692, 199, 2514, 1244, 1688, 136, 1244, 8168, 6284, 5671, 4019, 566, 4737, 853, 5182, 3544, 4172, 251, 7601, 255, 208, 687, 13599, 566, 755, 530, 128, 3071, 2223, 12929, 818, 336, 216, 128, 28811, 2163, 3189, 4814, 12080, 1992, 19599, 492, 853, 479, 1458, 1058, 103]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [7]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset data/test2.csv: 100%|██████████| 1028/1028 [00:01<00:00, 678.47 Dicts/s]\n",
            "11/28/2021 15:20:35 - INFO - farm.data_handler.data_silo -   \n",
            "11/28/2021 15:20:35 - INFO - farm.data_handler.data_silo -   DATASETS SUMMARY\n",
            "11/28/2021 15:20:35 - INFO - farm.data_handler.data_silo -   ================\n",
            "11/28/2021 15:20:35 - INFO - farm.data_handler.data_silo -   Examples in train: 7400\n",
            "11/28/2021 15:20:35 - INFO - farm.data_handler.data_silo -   Examples in dev  : 1845\n",
            "11/28/2021 15:20:35 - INFO - farm.data_handler.data_silo -   Examples in test : 1028\n",
            "11/28/2021 15:20:35 - INFO - farm.data_handler.data_silo -   \n",
            "11/28/2021 15:20:35 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     512\n",
            "11/28/2021 15:20:35 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 386.55405405405406\n",
            "11/28/2021 15:20:35 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.4239189189189189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct6zZopL11SB"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHaBvsO42J4T",
        "outputId": "cec19ef8-0afc-4071-afa2-9416e6707ad7"
      },
      "source": [
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import TextClassificationHead\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import set_all_seeds, initialize_device_settings\n",
        "\n",
        "set_all_seeds(seed=42)\n",
        "device, n_gpu = initialize_device_settings(use_cuda=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n",
            "11/28/2021 15:20:36 - INFO - faiss.loader -   Loading faiss with AVX2 support.\n",
            "11/28/2021 15:20:36 - INFO - faiss.loader -   Could not load library with AVX2 support due to:\n",
            "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
            "11/28/2021 15:20:36 - INFO - faiss.loader -   Loading faiss.\n",
            "11/28/2021 15:20:36 - INFO - faiss.loader -   Successfully loaded faiss.\n",
            "11/28/2021 15:20:36 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "11/28/2021 15:20:36 - INFO - farm.utils -   Using device: CUDA \n",
            "11/28/2021 15:20:36 - INFO - farm.utils -   Number of GPUs: 1\n",
            "11/28/2021 15:20:36 - INFO - farm.utils -   Distributed Training: False\n",
            "11/28/2021 15:20:36 - INFO - farm.utils -   Automatic Mixed Precision: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb-if7v713mE",
        "outputId": "2fbe0c96-a78d-4ec3-8296-983cab6410bb"
      },
      "source": [
        "# loading the pretrained BERT base cased model\n",
        "language_model = LanguageModel.load(checkpoint)\n",
        "\n",
        "# prediction head for our model that is suited for classifying news article genres\n",
        "prediction_head = TextClassificationHead(num_labels=len(label_list))\n",
        "\n",
        "model = AdaptiveModel(\n",
        "        language_model=language_model,\n",
        "        prediction_heads=[prediction_head],\n",
        "        embeds_dropout_prob=0.1,\n",
        "        lm_output_types=[\"per_sequence\"],\n",
        "        device=device)\n",
        "\n",
        "n_epochs = 1\n",
        "lr_rate = 3e-5\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "        model=model,\n",
        "        learning_rate=lr_rate,\n",
        "        device=device,\n",
        "        n_batches=len(data_silo.loaders[\"train\"]),\n",
        "        n_epochs=n_epochs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11/28/2021 15:20:36 - INFO - farm.modeling.language_model -   \n",
            "11/28/2021 15:20:36 - INFO - farm.modeling.language_model -   LOADING MODEL\n",
            "11/28/2021 15:20:36 - INFO - farm.modeling.language_model -   =============\n",
            "11/28/2021 15:20:36 - INFO - farm.modeling.language_model -   Could not find distilbert-base-german-cased locally.\n",
            "11/28/2021 15:20:36 - INFO - farm.modeling.language_model -   Looking on Transformers Model Hub (in local cache and online)...\n",
            "Some weights of the model checkpoint at distilbert-base-german-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "11/28/2021 15:20:38 - INFO - farm.modeling.language_model -   Automatically detected language from language model name: german\n",
            "11/28/2021 15:20:38 - INFO - farm.modeling.language_model -   Loaded distilbert-base-german-cased\n",
            "11/28/2021 15:20:38 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 9]\n",
            "11/28/2021 15:20:42 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 3e-05}'\n",
            "11/28/2021 15:20:43 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "11/28/2021 15:20:43 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 92.5, 'num_training_steps': 925}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39MQxcD07DnC"
      },
      "source": [
        "evaluate_every = 300\n",
        "\n",
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        data_silo=data_silo,\n",
        "        epochs=n_epochs,\n",
        "        n_gpu=n_gpu,\n",
        "        lr_schedule=lr_schedule,\n",
        "        evaluate_every=evaluate_every,\n",
        "        device=device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CppFbLr7Lir",
        "outputId": "aacde750-d280-4de4-c334-4fd6c1ce1162"
      },
      "source": [
        "%%time\n",
        "import logging\n",
        "\n",
        "# set to log level info to see very verbose output\n",
        "logging.getLogger(\"farm.train\").setLevel(logging.WARN)\n",
        "logging.getLogger(\"farm.eval\").setLevel(logging.WARN)\n",
        "\n",
        "model = trainer.train()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 0/0 (Cur. train loss: 0.8245):  32%|███▏      | 300/925 [01:29<02:32,  4.09it/s]\n",
            "Evaluating:   0%|          | 0/231 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 231/231 [00:16<00:00, 13.85it/s]\n",
            "Train epoch 0/0 (Cur. train loss: 0.1547):  65%|██████▍   | 600/925 [03:15<01:17,  4.20it/s]\n",
            "Evaluating:   0%|          | 0/231 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 231/231 [00:16<00:00, 13.86it/s]\n",
            "Train epoch 0/0 (Cur. train loss: 0.0506):  97%|█████████▋| 900/925 [05:01<00:06,  4.16it/s]\n",
            "Evaluating:   0%|          | 0/231 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 231/231 [00:16<00:00, 13.86it/s]\n",
            "Train epoch 0/0 (Cur. train loss: 0.3121): 100%|██████████| 925/925 [05:27<00:00,  2.83it/s]\n",
            "Evaluating: 100%|██████████| 129/129 [00:09<00:00, 13.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 35s, sys: 1.05 s, total: 4min 36s\n",
            "Wall time: 5min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y82-HOnHINU"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ica8dZlqFmSj"
      },
      "source": [
        "from farm.eval import Evaluator\n",
        "\n",
        "evaluator = Evaluator(\n",
        "    data_loader=data_silo.get_data_loader(\"test\"),\n",
        "    tasks=data_silo.processor.tasks,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mrYihVUGFbv",
        "outputId": "4123ad63-2c04-4d75-df60-76a14a279faa"
      },
      "source": [
        "results = evaluator.eval(model)\n",
        "\n",
        "print(f\"f1 macro: {results[0]['f1_macro']:.4}\")\n",
        "print(results[0]['report'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 129/129 [00:09<00:00, 13.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 macro: 0.8802\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Sport     0.9835    0.9917    0.9876       120\n",
            "       Kultur     0.9231    0.8889    0.9057        54\n",
            "          Web     0.9017    0.9286    0.9150       168\n",
            "   Wirtschaft     0.8356    0.8652    0.8502       141\n",
            "       Inland     0.8416    0.8333    0.8374       102\n",
            "         Etat     0.9153    0.8060    0.8571        67\n",
            "International     0.8936    0.8344    0.8630       151\n",
            "     Panorama     0.8171    0.8512    0.8338       168\n",
            " Wissenschaft     0.8500    0.8947    0.8718        57\n",
            "\n",
            "     accuracy                         0.8794      1028\n",
            "    macro avg     0.8846    0.8771    0.8802      1028\n",
            " weighted avg     0.8804    0.8794    0.8793      1028\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcggnn5YrfZS"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86gz3dOapbm6"
      },
      "source": [
        "from farm.infer import Inferencer"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}