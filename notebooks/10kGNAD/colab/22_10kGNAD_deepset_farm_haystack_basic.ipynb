{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "22_10kGNAD_deepset-farm-haystack_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPg6E5a/SzGsfLHU/AsRr67",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goerlitz/nlp-classification/blob/main/notebooks/10kGNAD/colab/22_10kGNAD_deepset_farm_haystack_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ei_ToiRvHiO"
      },
      "source": [
        "# Classifying German News Articles with deepset's Farm/Haystack\n",
        "\n",
        "NOTE: [deepset's Farm](https://github.com/deepset-ai/farm/) is now part of [deepset's Haystack](https://github.com/deepset-ai/haystack/). Still, the Farm documentation is helpful for classification implementation as haystack focuses on question answering.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "1. Train a text classifier with transfer learning based on a pretrained German transformer model.\n",
        "2. Simplify implementation by using [deepset's Farm](https://github.com/deepset-ai/FARM) library.\n",
        "\n",
        "based on https://towardsdatascience.com/fine-tuning-bert-for-text-classification-with-farm-2880665065e2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L01RmQaogkV"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMBjnHS8okJP"
      },
      "source": [
        "checkpoint = \"distilbert-base-german-cased\"\n",
        "\n",
        "# checkpoint = \"deepset/gbert-base\"\n",
        "\n",
        "# checkpoint = \"deepset/gelectra-base\"\n",
        "\n",
        "project_name = \"10kgnad_huggingface__\" + checkpoint.replace(\"/\", \"_\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihLF5YTqtQxz",
        "outputId": "f3e3209b-4dbb-4b9d-d598-bcfd6feb97de"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 28 16:10:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2lYW5A2o4z9"
      },
      "source": [
        "## Install and Configure Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36FFKPYhzDtG",
        "outputId": "873b67eb-2db7-4b3c-9415-8a05024f9d28"
      },
      "source": [
        "%%time\n",
        "# ensure the right torch versions (https://pytorch.org/get-started/previous-versions/)\n",
        "!pip install -q --upgrade torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 >/dev/null\n",
        "!pip install -q --upgrade farm-haystack >/dev/null\n",
        "\n",
        "# check installed version\n",
        "!pip freeze | grep transformers\n",
        "!pip freeze | grep farm\n",
        "!pip freeze | grep torch\n",
        "# transformers==4.6.1\n",
        "# farm==0.8.0\n",
        "# farm-haystack==0.10.0\n",
        "# torch==1.7.1\n",
        "# torchaudio==0.7.2\n",
        "# torchsummary==1.5.1\n",
        "# torchtext==0.8.1\n",
        "# torchvision==0.8.2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence-transformers==2.1.0\n",
            "transformers==4.6.1\n",
            "farm==0.8.0\n",
            "farm-haystack==0.10.0\n",
            "torch==1.7.1\n",
            "torchaudio==0.7.2\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.8.1\n",
            "torchvision==0.8.2\n",
            "CPU times: user 72.5 ms, sys: 31.6 ms, total: 104 ms\n",
            "Wall time: 9.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8cU2PM9ETJx"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import pandas as pd\n",
        "from pathlib import Path"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKUqNAfZo9E5"
      },
      "source": [
        "## Fetch Data\n",
        "\n",
        "Download [10k German News Articles Dataset](https://tblock.github.io/10kGNAD/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEcaedwWD66N",
        "outputId": "f8c329c9-ea2c-4df4-e04c-2670bea37f28"
      },
      "source": [
        "%env DIR=data\n",
        "\n",
        "!mkdir -p $DIR\n",
        "!wget -nc https://github.com/tblock/10kGNAD/blob/master/train.csv?raw=true -nv -O $DIR/train.csv\n",
        "!wget -nc https://github.com/tblock/10kGNAD/blob/master/test.csv?raw=true -nv -O $DIR/test.csv\n",
        "!ls -lAh $DIR | cut -d \" \" -f 5-"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: DIR=data\n",
            "\n",
            "2.7M Nov 28 15:56 test2.csv\n",
            "2.7M Nov 28 12:56 test.csv\n",
            " 24M Nov 28 15:56 train2.csv\n",
            " 24M Nov 28 12:56 train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuLSIj9NkXAG"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL2RFkuaaQug"
      },
      "source": [
        "data_dir = Path(os.getenv(\"DIR\"))\n",
        "\n",
        "train_file = data_dir / 'train.csv'\n",
        "test_file = data_dir / 'test.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8uT0utXQitf"
      },
      "source": [
        "def load_file(filepath: Path) -> pd.DataFrame:\n",
        "    f = pd.read_csv(filepath, sep=\";\", quotechar=\"'\", names=['labels', 'text'])\n",
        "    return f"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "pFMweinxRnAT",
        "outputId": "73a68930-ffe7-4124-aff4-b47eed00aa5f"
      },
      "source": [
        "train_df = load_file(data_dir / 'train.csv')\n",
        "train_df.to_csv(data_dir / 'train2.csv')\n",
        "print(f\"{train_df.shape[0]:,} articles\")\n",
        "display(train_df.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9,245 articles\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sport</td>\n",
              "      <td>21-Jähriger fällt wohl bis Saisonende aus. Wie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kultur</td>\n",
              "      <td>Erfundene Bilder zu Filmen, die als verloren g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Web</td>\n",
              "      <td>Der frischgekürte CEO Sundar Pichai setzt auf ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Putin: \"Einigung, dass wir Menge auf Niveau vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Inland</td>\n",
              "      <td>Estland sieht den künftigen österreichischen P...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       labels                                               text\n",
              "0       Sport  21-Jähriger fällt wohl bis Saisonende aus. Wie...\n",
              "1      Kultur  Erfundene Bilder zu Filmen, die als verloren g...\n",
              "2         Web  Der frischgekürte CEO Sundar Pichai setzt auf ...\n",
              "3  Wirtschaft  Putin: \"Einigung, dass wir Menge auf Niveau vo...\n",
              "4      Inland  Estland sieht den künftigen österreichischen P..."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "l5Vx3IriIYPK",
        "outputId": "ece7d977-fbb5-4d4c-b130-e08ab4b4ca52"
      },
      "source": [
        "test_df = load_file(data_dir / 'test.csv')\n",
        "test_df.to_csv(data_dir / 'test2.csv')\n",
        "print(f\"{test_df.shape[0]:,} articles\")\n",
        "display(test_df.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,028 articles\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wirtschaft</td>\n",
              "      <td>Die Gewerkschaft GPA-djp lanciert den \"All-in-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sport</td>\n",
              "      <td>Franzosen verteidigen 2:1-Führung – Kritische ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Web</td>\n",
              "      <td>Neues Video von Designern macht im Netz die Ru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sport</td>\n",
              "      <td>23-jähriger Brasilianer muss vier Spiele pausi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>International</td>\n",
              "      <td>Aufständische verwendeten Chemikalie bei Gefec...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          labels                                               text\n",
              "0     Wirtschaft  Die Gewerkschaft GPA-djp lanciert den \"All-in-...\n",
              "1          Sport  Franzosen verteidigen 2:1-Führung – Kritische ...\n",
              "2            Web  Neues Video von Designern macht im Netz die Ru...\n",
              "3          Sport  23-jähriger Brasilianer muss vier Spiele pausi...\n",
              "4  International  Aufständische verwendeten Chemikalie bei Gefec..."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmAiISLJIQuL"
      },
      "source": [
        "## Experiment Logging Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRdmk46kIUV5",
        "outputId": "c46d9b01-1a5f-40a8-fb9c-68d3acfe669d"
      },
      "source": [
        "from farm.utils import MLFlowLogger\n",
        "\n",
        "ml_logger = MLFlowLogger(tracking_uri=\"https://public-mlflow.deepset.ai/\")\n",
        "ml_logger.init_experiment(experiment_name=\"10kGNAD\", run_name=\"10kGNAD\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " __          __  _                            _        \n",
            " \\ \\        / / | |                          | |       \n",
            "  \\ \\  /\\  / /__| | ___ ___  _ __ ___   ___  | |_ ___  \n",
            "   \\ \\/  \\/ / _ \\ |/ __/ _ \\| '_ ` _ \\ / _ \\ | __/ _ \\ \n",
            "    \\  /\\  /  __/ | (_| (_) | | | | | |  __/ | || (_) |\n",
            "     \\/  \\/ \\___|_|\\___\\___/|_| |_| |_|\\___|  \\__\\___/ \n",
            "  ______      _____  __  __  \n",
            " |  ____/\\   |  __ \\|  \\/  |              _.-^-._    .--.\n",
            " | |__ /  \\  | |__) | \\  / |           .-'   _   '-. |__|\n",
            " |  __/ /\\ \\ |  _  /| |\\/| |          /     |_|     \\|  |\n",
            " | | / ____ \\| | \\ \\| |  | |         /               \\  |\n",
            " |_|/_/    \\_\\_|  \\_\\_|  |_|        /|     _____     |\\ |\n",
            "                                     |    |==|==|    |  |\n",
            "|---||---|---|---|---|---|---|---|---|    |--|--|    |  |\n",
            "|---||---|---|---|---|---|---|---|---|    |==|==|    |  |\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARWnT7ZWrhux"
      },
      "source": [
        "## Training Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntU6DQIrkeO"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl9aNAY71Eb8",
        "outputId": "c31d01c7-7968-45b9-a3f1-b4ba4bd814ef"
      },
      "source": [
        "# need to load transformer tokenizer first - FARM cannot infer lower case setting (it seems)\n",
        "do_lower_case = AutoTokenizer.from_pretrained(checkpoint).do_lower_case\n",
        "tokenizer = Tokenizer.load(checkpoint, do_lower_case=do_lower_case)\n",
        "tokenizer"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11/28/2021 16:11:03 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'DistilBertTokenizer'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='distilbert-base-german-cased', vocab_size=31102, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5jdOeOFtko3",
        "outputId": "cd06040b-5ede-4b56-ae18-6ee4265ffec9"
      },
      "source": [
        "label_list = list(train_df.labels.unique())\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from farm.evaluation.metrics import register_metrics\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "    return {\n",
        "        \"acc\": accuracy_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds, average='macro'),\n",
        "        \"precision\": precision_score(labels, preds, average='macro'),\n",
        "        \"recall\": recall_score(labels, preds, average='macro'),\n",
        "    }\n",
        "\n",
        "register_metrics('eval_metrics', compute_metrics)\n",
        "\n",
        "\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                        max_seq_len=tokenizer.model_max_length,\n",
        "                                        data_dir='data',\n",
        "                                        train_filename=\"train2.csv\",\n",
        "                                        dev_filename=None,\n",
        "                                        test_filename=\"test2.csv\",\n",
        "                                        quote_char='\"',\n",
        "                                        delimiter=\",\",\n",
        "                                        label_column_name=\"labels\",\n",
        "                                        label_list=label_list,\n",
        "                                        metric='eval_metrics'\n",
        "                                        # multilabel=True,\n",
        "                                        # dev_split=0.1 # this will extract 10% of the train set to create a dev set\n",
        "                                        )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11/28/2021 16:11:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jON9TIbO0kqh",
        "outputId": "f42dbfde-8bf2-4cd2-9419-b80b0a124117"
      },
      "source": [
        "batch_size = 32 # larger batch sizes might use too much computing power in Colab\n",
        "\n",
        "# set log level to INFO to see very verbose output\n",
        "logging.getLogger(\"farm.data_handler.data_silo\").setLevel(logging.WARN)\n",
        "logging.getLogger(\"farm.data_handler.processor\").setLevel(logging.WARN)\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing Dataset data/train2.csv: 100%|██████████| 9245/9245 [00:10<00:00, 858.49 Dicts/s]\n",
            "Preprocessing Dataset data/test2.csv: 100%|██████████| 1028/1028 [00:01<00:00, 679.47 Dicts/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct6zZopL11SB"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHaBvsO42J4T",
        "outputId": "b6ac03cf-65f6-4a8a-9970-ba11d7b5a2ac"
      },
      "source": [
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import TextClassificationHead\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import set_all_seeds, initialize_device_settings\n",
        "\n",
        "set_all_seeds(seed=42)\n",
        "device, n_gpu = initialize_device_settings(use_cuda=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n",
            "11/28/2021 16:11:18 - INFO - faiss.loader -   Loading faiss with AVX2 support.\n",
            "11/28/2021 16:11:18 - INFO - faiss.loader -   Could not load library with AVX2 support due to:\n",
            "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
            "11/28/2021 16:11:18 - INFO - faiss.loader -   Loading faiss.\n",
            "11/28/2021 16:11:18 - INFO - faiss.loader -   Successfully loaded faiss.\n",
            "11/28/2021 16:11:19 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "11/28/2021 16:11:19 - INFO - farm.utils -   Using device: CUDA \n",
            "11/28/2021 16:11:19 - INFO - farm.utils -   Number of GPUs: 1\n",
            "11/28/2021 16:11:19 - INFO - farm.utils -   Distributed Training: False\n",
            "11/28/2021 16:11:19 - INFO - farm.utils -   Automatic Mixed Precision: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb-if7v713mE",
        "outputId": "1e08fd06-4fc8-45fd-bd4f-2861763869b8"
      },
      "source": [
        "# loading the pretrained BERT base cased model\n",
        "language_model = LanguageModel.load(checkpoint)\n",
        "\n",
        "# prediction head for our model that is suited for classifying news article genres\n",
        "prediction_head = TextClassificationHead(num_labels=len(label_list))\n",
        "\n",
        "model = AdaptiveModel(\n",
        "        language_model=language_model,\n",
        "        prediction_heads=[prediction_head],\n",
        "        embeds_dropout_prob=0.1,\n",
        "        lm_output_types=[\"per_sequence\"],\n",
        "        device=device)\n",
        "\n",
        "n_epochs = 1\n",
        "lr_rate = 3e-5\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "        model=model,\n",
        "        learning_rate=lr_rate,\n",
        "        device=device,\n",
        "        n_batches=len(data_silo.loaders[\"train\"]),\n",
        "        n_epochs=n_epochs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11/28/2021 16:11:19 - INFO - farm.modeling.language_model -   \n",
            "11/28/2021 16:11:19 - INFO - farm.modeling.language_model -   LOADING MODEL\n",
            "11/28/2021 16:11:19 - INFO - farm.modeling.language_model -   =============\n",
            "11/28/2021 16:11:19 - INFO - farm.modeling.language_model -   Could not find distilbert-base-german-cased locally.\n",
            "11/28/2021 16:11:19 - INFO - farm.modeling.language_model -   Looking on Transformers Model Hub (in local cache and online)...\n",
            "Some weights of the model checkpoint at distilbert-base-german-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "11/28/2021 16:11:21 - INFO - farm.modeling.language_model -   Automatically detected language from language model name: german\n",
            "11/28/2021 16:11:21 - INFO - farm.modeling.language_model -   Loaded distilbert-base-german-cased\n",
            "11/28/2021 16:11:21 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 9]\n",
            "11/28/2021 16:11:24 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 3e-05}'\n",
            "11/28/2021 16:11:26 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "11/28/2021 16:11:26 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 23.200000000000003, 'num_training_steps': 232}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39MQxcD07DnC"
      },
      "source": [
        "evaluate_every = 100\n",
        "\n",
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        data_silo=data_silo,\n",
        "        epochs=n_epochs,\n",
        "        n_gpu=n_gpu,\n",
        "        lr_schedule=lr_schedule,\n",
        "        evaluate_every=evaluate_every,\n",
        "        device=device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CppFbLr7Lir",
        "outputId": "0993420c-5a82-447b-a3d1-278ea64dc692"
      },
      "source": [
        "%%time\n",
        "import logging\n",
        "\n",
        "# set log level to INFO to see very verbose output\n",
        "logging.getLogger(\"farm.train\").setLevel(logging.WARN)\n",
        "logging.getLogger(\"farm.eval\").setLevel(logging.WARN)\n",
        "\n",
        "model = trainer.train()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 0/0 (Cur. train loss: 0.6563):  43%|████▎     | 100/232 [01:30<01:51,  1.18it/s]\n",
            "Evaluating:   0%|          | 0/58 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 58/58 [00:15<00:00,  3.74it/s]\n",
            "Train epoch 0/0 (Cur. train loss: 0.3198):  86%|████████▌ | 200/232 [03:16<00:26,  1.22it/s]\n",
            "Evaluating:   0%|          | 0/58 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 58/58 [00:15<00:00,  3.74it/s]\n",
            "Train epoch 0/0 (Cur. train loss: 0.4943): 100%|██████████| 232/232 [04:02<00:00,  1.05s/it]\n",
            "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 51s, sys: 469 ms, total: 3min 51s\n",
            "Wall time: 4min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y82-HOnHINU"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ica8dZlqFmSj"
      },
      "source": [
        "from farm.eval import Evaluator\n",
        "\n",
        "evaluator = Evaluator(\n",
        "    data_loader=data_silo.get_data_loader(\"test\"),\n",
        "    tasks=data_silo.processor.tasks,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mrYihVUGFbv",
        "outputId": "db7d86a0-0eff-47ec-d26c-10b5a321e714"
      },
      "source": [
        "results = evaluator.eval(model)\n",
        "\n",
        "print(\"\\n\", results[0]['report'])\n",
        "\n",
        "for metric in [\"loss\", \"acc\", \"f1\", \"precision\", \"recall\"]:\n",
        "    print(f\"{metric}: {results[0][metric]:.4}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "        Sport     0.9754    0.9917    0.9835       120\n",
            "       Kultur     0.9038    0.8704    0.8868        54\n",
            "          Web     0.9070    0.9286    0.9176       168\n",
            "   Wirtschaft     0.8298    0.8298    0.8298       141\n",
            "       Inland     0.8280    0.7549    0.7897       102\n",
            "         Etat     0.8906    0.8507    0.8702        67\n",
            "International     0.8639    0.8411    0.8523       151\n",
            "     Panorama     0.7910    0.8333    0.8116       168\n",
            " Wissenschaft     0.8333    0.8772    0.8547        57\n",
            "\n",
            "     accuracy                         0.8658      1028\n",
            "    macro avg     0.8692    0.8642    0.8663      1028\n",
            " weighted avg     0.8659    0.8658    0.8655      1028\n",
            "\n",
            "loss: 0.3782\n",
            "acc: 0.8658\n",
            "f1: 0.8663\n",
            "precision: 0.8692\n",
            "recall: 0.8642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcggnn5YrfZS"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86gz3dOapbm6"
      },
      "source": [
        "from farm.infer import Inferencer"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}